{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "host = \"database-job-posts.c1qytdm4eno0.us-east-1.rds.amazonaws.com\"\n",
    "\n",
    "port =int(3306)\n",
    "dbname=\"job_posts\"\n",
    "user=\"timaun4db\"\n",
    "password=\"WSsmdIep4db2e\"\n",
    "conn = pymysql.connect(host, user=user,port=port, passwd=password, db=dbname,charset='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322057, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 =pd.read_sql('SELECT * from temp_data', con=conn)\n",
    "data1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319719, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### remove wrong data collection\n",
    "data_correct = data1[data1['date'] !='''If you require alternative methods of application or screening, you must approach the employer directly to request this as Indeed is not responsible for the employer's application process.''']\n",
    "data_correct.shape              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mh4pk\\AppData\\Local\\Continuum\\anaconda3\\envs\\scrapyenv2\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "data_correct.drop(['date','day'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319719, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_correct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261110, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping duplicates due to overlap of periods\n",
    "no_overlap_data=data_correct[~data_correct.duplicated()]\n",
    "no_overlap_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy a backup of data to hard drive\n",
    "no_overlap_data.to_csv('April-10-backup.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "retrived_data = pd.read_csv('C:/Users/mh4pk/Downloads/April-10-backup.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244681, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droped_dup_data = retrived_data[~retrived_data[['job_title', 'company', 'description',\n",
    "       'state', 'city','posted_date']].duplicated()]\n",
    "droped_dup_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'data analyst': 129321,\n",
       "         'machine learning engineer': 71997,\n",
       "         'data scientist': 43363})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(droped_dup_data.term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "CA                                         32384\n",
      "TX                                         15714\n",
      "VA                                         14711\n",
      "NY                                         14297\n",
      "WA                                         13779\n",
      "IL                                         10049\n",
      "MA                                          9632\n",
      "FL                                          8169\n",
      "DC                                          8124\n",
      "PA                                          7951\n",
      "MD                                          7578\n",
      "NC                                          7430\n",
      "GA                                          6842\n",
      "NJ                                          6672\n",
      "OH                                          5443\n",
      "CO                                          5182\n",
      "MN                                          4455\n",
      "AZ                                          4152\n",
      "MI                                          4142\n",
      "MO                                          3465\n",
      "TN                                          3037\n",
      "CT                                          2628\n",
      "WI                                          2380\n",
      "OR                                          2279\n",
      "IN                                          2164\n",
      "UT                                          2128\n",
      "AL                                          1631\n",
      "IA                                          1566\n",
      "DE                                          1529\n",
      "SC                                          1522\n",
      "In                                          1241\n",
      "KY                                          1179\n",
      "KS                                          1045\n",
      "AR                                           972\n",
      "California                                   955\n",
      "NM                                           886\n",
      "NE                                           871\n",
      "LA                                           839\n",
      "OK                                           835\n",
      "ID                                           809\n",
      "NV                                           756\n",
      "RI                                           600\n",
      "HI                                           579\n",
      "NH                                           550\n",
      "Texas                                        527\n",
      "New York State                               526\n",
      "LL                                           474\n",
      "United States                                439\n",
      "ME                                           436\n",
      "MS                                           392\n",
      "PR                                           367\n",
      "Virginia                                     286\n",
      "Massachusetts                                284\n",
      "WV                                           273\n",
      "MT                                           272\n",
      "AK                                           259\n",
      "Illinois                                     257\n",
      "Washington State                             230\n",
      "Colorado                                     220\n",
      "Georgia                                      218\n",
      "VT                                           205\n",
      "New Jersey                                   200\n",
      "ND                                           196\n",
      "SD                                           195\n",
      "North Carolina                               185\n",
      "Michigan                                     178\n",
      "Florida                                      170\n",
      "Pennsylvania                                 152\n",
      "Maryland                                     150\n",
      "Oregon                                       135\n",
      "WY                                           125\n",
      "Arizona                                      123\n",
      "Gainwell Technologies                        108\n",
      "Ohio                                         105\n",
      "Minnesota                                    100\n",
      "Indiana                                       96\n",
      "TuSimple                                      75\n",
      "Missouri                                      67\n",
      "N.                                            65\n",
      "Tennessee                                     62\n",
      "Motional                                      62\n",
      "Frontdoor                                     60\n",
      "South Carolina                                56\n",
      "Utah                                          55\n",
      "Connecticut                                   54\n",
      "Delaware                                      51\n",
      "The Blue Store                                49\n",
      "Iowa                                          45\n",
      "Oklahoma                                      43\n",
      "Textio                                        42\n",
      "Nevada                                        41\n",
      "Alldus                                        41\n",
      "Layer 7 Data Solutions                        41\n",
      "Alabama                                       37\n",
      "Elign Consulting                              37\n",
      "Wisconsin                                     37\n",
      "Hawaii                                        35\n",
      "Okaya Corp                                    34\n",
      "iknowvate technologies                        34\n",
      "Nebraska                                      34\n",
      "Soar Technology                               32\n",
      "Arkansas                                      32\n",
      "Legalist                                      31\n",
      "Kansas                                        30\n",
      "SphereOI Studios                              29\n",
      "Rebellion Defense                             29\n",
      "Louisiana                                     26\n",
      "VI                                            26\n",
      "Kentucky                                      26\n",
      "Digital Dhara                                 26\n",
      "Rhode Island                                  25\n",
      "Idaho                                         24\n",
      "CCS Global Tech                               24\n",
      "Kani Solutions                                23\n",
      "AlignTech                                     23\n",
      "First Notch Technology LLC                    23\n",
      "Infolob                                       23\n",
      "West Virginia                                 23\n",
      "Tapad                                         22\n",
      "PHASTAR                                       22\n",
      "EnergyHub                                     22\n",
      "Energy Solutionss                             22\n",
      "Equitus                                       22\n",
      "Amply Media                                   22\n",
      "Databricks                                    22\n",
      "Darkblade Systems Corporation                 22\n",
      "FlexIT Inc                                    21\n",
      "RCI                                           20\n",
      "Compass                                       20\n",
      "Alaska                                        20\n",
      "Paradigm Diagnostics                          20\n",
      "Guam                                          19\n",
      "Clinical Score                                19\n",
      "Montana                                       19\n",
      "Kin + Carta                                   19\n",
      "TA Digital                                    18\n",
      "Hired Recruiters                              18\n",
      "Syrinx                                        18\n",
      "Prescient Edge Federal                        18\n",
      "Gras Savoye                                   18\n",
      "New Mexico                                    18\n",
      "Wyoming                                       18\n",
      "Resiliency LLC                                17\n",
      "Stord - other locations                       17\n",
      "Freenome Holdings                             17\n",
      "Mississippi                                   17\n",
      "Valo Health                                   17\n",
      "Olympus Corporation of the Americas           17\n",
      "Perceptive Automata                           17\n",
      "US Department of Education                    17\n",
      "North Dakota                                  17\n",
      "Agiloft                                       16\n",
      "Recursion                                     16\n",
      "VulcanForms                                   16\n",
      "Tekla Research                                16\n",
      "Known                                         16\n",
      "New Hampshire                                 16\n",
      "Aktify                                        16\n",
      "DAtec                                         16\n",
      "AURA TECHNOLOGIES LLC.                        15\n",
      "Avantus Federal                               15\n",
      "Martin Defense Group                          15\n",
      "Pricesenz                                     15\n",
      "Morton                                        15\n",
      "SAGE Black Consulting & Contracting LLC       15\n",
      "Tech Army                                     14\n",
      "Iscientiaus                                   14\n",
      "HBO Max                                       14\n",
      "IonQ                                          14\n",
      "Na                                            14\n",
      "Snowflake                                     14\n",
      "Vision                                        14\n",
      "Puerto Rico                                   14\n",
      "Kani Solutions Inc.                           14\n",
      "Datto Jobs                                    14\n",
      "Cash App                                      14\n",
      "LaborView                                     14\n",
      "Vermont                                       14\n",
      "540                                           14\n",
      "Confidential                                  14\n",
      "GU                                            14\n",
      "Calypso Way                                   14\n",
      "AbSci                                         14\n",
      "Integrated Data Services Inc.                 14\n",
      "Lt                                            13\n",
      "The DarkStar Group LLC                        13\n",
      "Northrop Grumman                              13\n",
      "Flock Safety                                  13\n",
      "Cimpress/Vistaprint                           13\n",
      "Corvus Insurance                              13\n",
      "BLST Operating Company LLC                    13\n",
      "Elutions                                      13\n",
      "Mesh Plus Plus                                13\n",
      "Hitachi Vantara Corporation                   13\n",
      "Tiger Analytics                               13\n",
      "SimBioSys                                     12\n",
      "The Mom Project                               12\n",
      "Gallega Software Solutions Inc                12\n",
      "Murmuration                                   12\n",
      "Wavious                                       12\n",
      "Name: posted_date, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    " print(droped_dup_data.groupby('state')['posted_date'].count().sort_values(ascending =False).head(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223719, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### there are missing state filled in our data.\n",
    "list_of_us_codes = ['AK', 'AL', 'AR', 'AS', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'GU', 'HI',\n",
    "                    'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MP',\n",
    "                    'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI',\n",
    "                    'SC', 'SD', 'TN', 'TX', 'UM', 'UT', 'VA', 'VI', 'VT', 'WA', 'WI', 'WV', 'WY']\n",
    "dd = droped_dup_data[droped_dup_data.state.isin(list_of_us_codes)]\n",
    "dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alabama': 'AL',\n",
       " 'Alaska': 'AK',\n",
       " 'Arizona': 'AZ',\n",
       " 'Arkansas': 'AR',\n",
       " 'California': 'CA',\n",
       " 'Colorado': 'CO',\n",
       " 'Connecticut': 'CT',\n",
       " 'Delaware': 'DE',\n",
       " 'Florida': 'FL',\n",
       " 'Georgia': 'GA',\n",
       " 'Hawaii': 'HI',\n",
       " 'Idaho': 'ID',\n",
       " 'Illinois': 'IL',\n",
       " 'Indiana': 'IN',\n",
       " 'Iowa': 'IA',\n",
       " 'Kansas': 'KS',\n",
       " 'Kentucky': 'KY',\n",
       " 'Louisiana': 'LA',\n",
       " 'Maine': 'ME',\n",
       " 'Maryland': 'MD',\n",
       " 'Massachusetts': 'MA',\n",
       " 'Michigan': 'MI',\n",
       " 'Minnesota': 'MN',\n",
       " 'Mississippi': 'MS',\n",
       " 'Missouri': 'MO',\n",
       " 'Montana': 'MT',\n",
       " 'Nebraska': 'NE',\n",
       " 'Nevada': 'NV',\n",
       " 'New Hampshire': 'NH',\n",
       " 'New Jersey': 'NJ',\n",
       " 'New Mexico': 'NM',\n",
       " 'New York State': 'NY',\n",
       " 'North Carolina': 'NC',\n",
       " 'North Dakota': 'ND',\n",
       " 'Ohio': 'OH',\n",
       " 'Oklahoma': 'OK',\n",
       " 'Oregon': 'OR',\n",
       " 'Pennsylvania': 'PA',\n",
       " 'Rhode Island': 'RI',\n",
       " 'South Carolina': 'SC',\n",
       " 'South Dakota': 'SD',\n",
       " 'Tennessee': 'TN',\n",
       " 'Texas': 'TX',\n",
       " 'Utah': 'UT',\n",
       " 'Vermont': 'VT',\n",
       " 'Virginia': 'VA',\n",
       " 'Washington State': 'WA',\n",
       " 'West Virginia': 'WV',\n",
       " 'Wisconsin': 'WI',\n",
       " 'Wyoming': 'WY'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_state_abbrev = {\n",
    "    'AL': 'Alabama',\n",
    "    'AK': 'Alaska',\n",
    "    'AZ': 'Arizona',\n",
    "    'AR': 'Arkansas',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'IA': 'Iowa',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi',\n",
    "    'MO': 'Missouri',\n",
    "    'MT': 'Montana',\n",
    "    'NE': 'Nebraska',\n",
    "    'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NY': 'New York State',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VT': 'Vermont',\n",
    "    'VA': 'Virginia',\n",
    "    'WA': 'Washington State',\n",
    "    'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WY': 'Wyoming',\n",
    "}\n",
    "us_state_abbrev_reversed = dict(zip(us_state_abbrev.values(), us_state_abbrev.keys()))\n",
    "us_state_abbrev_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_states(state):\n",
    "    if state in us_state_abbrev_reversed.keys():\n",
    "        return us_state_abbrev_reversed[state]\n",
    "    else:\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mh4pk\\AppData\\Local\\Continuum\\anaconda3\\envs\\scrapyenv2\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "droped_dup_data['state']=droped_dup_data['state'].apply(fix_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "CA                       33339\n",
      "TX                       16241\n",
      "VA                       14997\n",
      "NY                       14823\n",
      "WA                       14009\n",
      "IL                       10306\n",
      "MA                        9916\n",
      "FL                        8339\n",
      "DC                        8124\n",
      "PA                        8103\n",
      "MD                        7728\n",
      "NC                        7615\n",
      "GA                        7060\n",
      "NJ                        6872\n",
      "OH                        5548\n",
      "CO                        5402\n",
      "MN                        4555\n",
      "MI                        4320\n",
      "AZ                        4275\n",
      "MO                        3532\n",
      "TN                        3099\n",
      "CT                        2682\n",
      "WI                        2417\n",
      "OR                        2414\n",
      "IN                        2260\n",
      "UT                        2183\n",
      "AL                        1668\n",
      "IA                        1611\n",
      "DE                        1580\n",
      "SC                        1578\n",
      "In                        1241\n",
      "KY                        1205\n",
      "KS                        1075\n",
      "AR                        1004\n",
      "NE                         905\n",
      "NM                         904\n",
      "OK                         878\n",
      "LA                         865\n",
      "ID                         833\n",
      "NV                         797\n",
      "RI                         625\n",
      "HI                         614\n",
      "NH                         566\n",
      "LL                         474\n",
      "ME                         444\n",
      "United States              439\n",
      "MS                         409\n",
      "PR                         367\n",
      "WV                         296\n",
      "MT                         291\n",
      "AK                         279\n",
      "VT                         219\n",
      "ND                         213\n",
      "SD                         203\n",
      "WY                         143\n",
      "Gainwell Technologies      108\n",
      "TuSimple                    75\n",
      "N.                          65\n",
      "Motional                    62\n",
      "Frontdoor                   60\n",
      "Name: posted_date, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    " print(droped_dup_data.groupby('state')['posted_date'].count().sort_values(ascending =False).head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = droped_dup_data.groupby('state')['posted_date'].count().sort_values(ascending =False).head(55)\n",
    "distributions = dist.drop(labels=['LL','United States'])\n",
    "distributions.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights =distributions.tolist()\n",
    "dd3=droped_dup_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = distributions.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def fix_missing_state(state):\n",
    "    if state not in list_of_us_codes:\n",
    "        ret =(random.choices(state_list, weights =weights ))\n",
    "        return ret[0]\n",
    "    else:\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd3['state'] =dd3['state'].apply(fix_missing_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IL'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd3.iloc[25]['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "CA    35446\n",
      "TX    17324\n",
      "VA    15971\n",
      "NY    15807\n",
      "WA    14937\n",
      "IL    10941\n",
      "MA    10528\n",
      "FL     8910\n",
      "DC     8641\n",
      "PA     8620\n",
      "MD     8252\n",
      "NC     8119\n",
      "GA     7464\n",
      "NJ     7322\n",
      "OH     5914\n",
      "CO     5764\n",
      "MN     4832\n",
      "MI     4580\n",
      "AZ     4560\n",
      "MO     3776\n",
      "TN     3295\n",
      "CT     2848\n",
      "OR     2599\n",
      "WI     2561\n",
      "IN     2393\n",
      "UT     2315\n",
      "AL     1766\n",
      "IA     1713\n",
      "SC     1700\n",
      "DE     1685\n",
      "KY     1277\n",
      "KS     1146\n",
      "AR     1067\n",
      "NM      967\n",
      "NE      954\n",
      "OK      944\n",
      "LA      935\n",
      "ID      882\n",
      "NV      863\n",
      "RI      661\n",
      "HI      648\n",
      "NH      601\n",
      "ME      469\n",
      "MS      442\n",
      "PR      392\n",
      "WV      307\n",
      "MT      305\n",
      "AK      296\n",
      "VT      232\n",
      "ND      230\n",
      "Name: posted_date, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    " print(dd3.groupby('state')['posted_date'].count().sort_values(ascending =False).head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd3.to_csv('C:/Users/mh4pk/Downloads/april-10-fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dd3.reset_index(inplace =True)\n",
    "ss= dd3.groupby('company')['posted_date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company\n",
       "Amazon.com Services LLC           7251\n",
       "JPMorgan Chase Bank, N.A.         3873\n",
       "Deloitte                          3461\n",
       "Wells Fargo                       2030\n",
       "Amazon Web Services, Inc.         1850\n",
       "Microsoft                         1661\n",
       "Accenture                         1474\n",
       "Pearson                           1388\n",
       "Booz Allen Hamilton               1266\n",
       "Apple                             1243\n",
       "Capital One - US                  1166\n",
       "US Department of the Air Force    1103\n",
       "CACI                              1084\n",
       "Amazon Dev Center U.S., Inc.      1082\n",
       "Facebook                          1069\n",
       "Thermo Fisher Scientific          1037\n",
       "US Department of the Navy          999\n",
       "US Department of the Army          969\n",
       "UnitedHealth Group                 967\n",
       "Capital One                        950\n",
       "Name: posted_date, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add match skills columns to our dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_df = pd.read_csv('C:\\\\Users\\\\mh4pk\\\\Downloads\\\\data_science_tags.csv', index_col = 'Unnamed: 0')\n",
    "skills_df = skills_df.rename(columns={\"0\": \"tag\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_and_skills = pd.concat([\n",
    "        dd3,pd.DataFrame(\n",
    "            [[0]*len(skills_df)], \n",
    "            index=dd.index, \n",
    "            columns=[tag for tag in skills_df['tag']])],axis =1)\n",
    "jobs_and_skills['description']=jobs_and_skills.description.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def match_regex(text,a_tag):\n",
    "    \n",
    "    pattern = re.compile(r\"[\\s ,(]\"+ re.escape(a_tag)+\"[\\s,),\\.,,,;]\")\n",
    "    \n",
    "    res = pattern.search(text)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7h 20min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(jobs_and_skills.index)):\n",
    "    for tag in skills_df['tag']:\n",
    "        if match_regex(jobs_and_skills.description[i],tag):\n",
    "            jobs_and_skills.at[i,tag]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_and_skills.to_csv('C:\\\\Users\\\\mh4pk\\\\Downloads\\\\final_clean_job_and_skills.cvs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## working on clean data to reduce skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "jobs_skills = pd.read_csv('C:\\\\Users\\\\mh4pk\\\\Downloads\\\\final_clean_job_and_skills.cvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jobs_skills' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b7c7f2c626a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjobs_skills\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'jobs_skills' is not defined"
     ]
    }
   ],
   "source": [
    "jobs_skills.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirichlet                           60\n",
      "mcmc                                60\n",
      "ensemble learning                   58\n",
      "domain adaptation                   57\n",
      "activity recognition                57\n",
      "explainable ai                      55\n",
      "parameter estimation                55\n",
      "speech to text                      55\n",
      "ipython                             52\n",
      "stanford nlp                        52\n",
      "pip                                 51\n",
      "interpolation                       50\n",
      "networkx                            49\n",
      "learning to rank                    49\n",
      "fasttext                            49\n",
      "siamese networks                    48\n",
      "amazon ml                           47\n",
      "discriminant analysis               45\n",
      "fuzzy logic                         45\n",
      "dataframe                           43\n",
      "gru                                 42\n",
      "data leakage                        42\n",
      "handwritten                         41\n",
      "sequence to sequence                41\n",
      "multitask learning                  40\n",
      "rdkit                               40\n",
      "gradient descent                    39\n",
      "mlp                                 38\n",
      "spyder                              36\n",
      "deep network                        34\n",
      "text generation                     33\n",
      "relational dbms                     31\n",
      "data.table                          31\n",
      "vae                                 31\n",
      "python 3.x                          28\n",
      "featurization                       28\n",
      "natural language process            28\n",
      "similar documents                   27\n",
      "ab test                             27\n",
      "markov process                      26\n",
      "topic model                         26\n",
      "pyro                                26\n",
      "dbscan                              25\n",
      "dropout                             24\n",
      "wikipedia                           24\n",
      "apache mahout                       24\n",
      "mse                                 22\n",
      "esl                                 22\n",
      "manifold                            22\n",
      "gmm                                 22\n",
      "gluon                               21\n",
      "gaussian process                    21\n",
      "allennlp                            21\n",
      "non parametric                      19\n",
      "colab                               19\n",
      "pickle                              19\n",
      "k means                             19\n",
      "density estimation                  18\n",
      "isolation forest                    18\n",
      "elastic net                         16\n",
      "doc2vec                             16\n",
      "huggingface                         16\n",
      "feature reduction                   15\n",
      "adaboost                            15\n",
      "genetic programming                 14\n",
      "autoencoder                         13\n",
      "gnn                                 13\n",
      "perceptron                          13\n",
      "expectation maximization            13\n",
      "svr                                 13\n",
      "openai gym                          12\n",
      "randomized algorithms               12\n",
      "sparsity                            12\n",
      "backpropagation                     11\n",
      "convnet                             11\n",
      "fastai                              10\n",
      "tranformation                       10\n",
      "loss function                        9\n",
      "class imbalance                      9\n",
      "heatmap                              9\n",
      "ridge regression                     9\n",
      "feature scaling                      9\n",
      "igraph                               8\n",
      "graph neural network                 8\n",
      "tfidf                                8\n",
      "feature map                          8\n",
      "groupby                              8\n",
      "pgm                                  7\n",
      "rbf                                  7\n",
      "crisp dm                             7\n",
      "hog                                  7\n",
      "self study                           7\n",
      "objective function                   7\n",
      "language model                       7\n",
      "google prediction api                6\n",
      "3d object detection                  6\n",
      "rattle                               6\n",
      "evolutionary algorithms              6\n",
      "rmse                                 6\n",
      "grid search                          6\n",
      "vgg16                                5\n",
      "feature construction                 5\n",
      "rbm                                  5\n",
      "bayesian nonparametric               5\n",
      "pytorch geometric                    5\n",
      "learning rate                        4\n",
      "multilabel classification            4\n",
      "usecase                              4\n",
      "graphical model                      4\n",
      "weighted data                        4\n",
      "faster rcnn                          3\n",
      "unbalanced classes                   3\n",
      "finetuning                           3\n",
      "unseen data                          3\n",
      "activation function                  3\n",
      "tsne                                 3\n",
      "softmax                              3\n",
      "groundtruth                          2\n",
      "spectral clustering                  2\n",
      "pybrain                              2\n",
      "structural equation modelling        2\n",
      "q learning                           2\n",
      "hierarchical data format             2\n",
      "multi output                         2\n",
      "glorot initialization                2\n",
      "audio recognition                    2\n",
      "probability calibration              2\n",
      "bootstraping                         1\n",
      "vector space models                  1\n",
      "actor critic                         1\n",
      "libsvm                               1\n",
      "wolfram language                     1\n",
      "causalimpact                         1\n",
      "early stopping                       1\n",
      "mutual information                   1\n",
      "goss                                 1\n",
      "multivariate distribution            1\n",
      "naive bayes classifier               1\n",
      "target encoding                      1\n",
      "openai gpt                           1\n",
      "serialisation                        1\n",
      "multiclass classification            1\n",
      "attention mechanism                  1\n",
      "dqn                                  1\n",
      "mean shift                           1\n",
      "mnist                                1\n",
      "open set                             1\n",
      "ndcg                                 1\n",
      "smote                                1\n",
      "epochs                               1\n",
      "neuralnetwork                        0\n",
      "exploratory factor analysis          0\n",
      "hashingvectorizer                    0\n",
      "vc theory                            0\n",
      "sematic similarity                   0\n",
      "multi agent                          0\n",
      "infere                               0\n",
      "hinge loss                           0\n",
      "skorch                               0\n",
      "naive bayes algorithim               0\n",
      "alex net                             0\n",
      "inceptionresnetv2                    0\n",
      "spatial transformer                  0\n",
      "helmert coding                       0\n",
      "jaccard coefficient                  0\n",
      "summarunner architecture             0\n",
      "keras rl                             0\n",
      "spearmans rank correlation           0\n",
      "pac learning                         0\n",
      "cs231n                               0\n",
      "james stein encoder                  0\n",
      "collinearity                         0\n",
      "multi instance learning              0\n",
      "discounted reward                    0\n",
      "natural gradient boosting            0\n",
      "tflearn                              0\n",
      "least squares svm                    0\n",
      "hurdle model                         0\n",
      "bayes error                          0\n",
      "proximal svm                         0\n",
      "predictor importance                 0\n",
      "data indexing techniques             0\n",
      "separable                            0\n",
      "estimation updating                  0\n",
      "cosine distance                      0\n",
      "policy gradients                     0\n",
      "batch normalization                  0\n",
      "weight initialization                0\n",
      "orange3                              0\n",
      "matrix factorisation                 0\n",
      "linearly separable                   0\n",
      "markov hidden model                  0\n",
      "gridsearchcv                         0\n",
      "image size                           0\n",
      "kerastuner                           0\n",
      "sequential pattern mining            0\n",
      "pearsons correlation coefficient     0\n",
      "bayesian neural network              0\n",
      "fuzzy classification                 0\n",
      "movielens                            0\n",
      "semi supervised learning             0\n",
      "mini batch gradient descent          0\n",
      "imbalanced learn                     0\n",
      "kitti dataset                        0\n",
      "extreme learning machine             0\n",
      "finite precision                     0\n",
      "software recommendation              0\n",
      "rmsle                                0\n",
      "cost function                        0\n",
      "one hot encoding                     0\n",
      "freebase                             0\n",
      "categorical encoding                 0\n",
      "lda classifier                       0\n",
      "smotenc                              0\n",
      "historgram                           0\n",
      "graphviz                             0\n",
      "recurrent neural net                 0\n",
      "neural style transfer                0\n",
      "nl2sql                               0\n",
      "skmultilearn                         0\n",
      "galago                               0\n",
      "ngboost                              0\n",
      "data stream mining                   0\n",
      "f1score                              0\n",
      "one shot learning                    0\n",
      "ngrams                               0\n",
      "stacked lstm                         0\n",
      "k nn                                 0\n",
      "marginal effects                     0\n",
      "normal equation                      0\n",
      "image preprocessing                  0\n",
      "chi square test                      0\n",
      "functional api                       0\n",
      "text filter                          0\n",
      "dummy variables                      0\n",
      "automatic summarization              0\n",
      "consumerweb                          0\n",
      "reference request                    0\n",
      "noisification                        0\n",
      "kendalls tau coefficient             0\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(jobs_skills.iloc[:,8:].sum().astype(int).sort_values(ascending= False).tail(240).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail=jobs_skills.iloc[:,8:].sum().astype(int).sort_values(ascending= False).tail(240).index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_list = ['data', 'dataset','machine learning model', 'training','loss function','data science model','categorical data', 'correlation', 'backpropagation','accuracy'\n",
    ",'similarity','evaluation','outlier','performance','regularization', 'missing data','sampling', 'hyperparameter','metric','distribution','text', 'encoding', 'activation function', 'kaggle',\n",
    "'python 3.x', 'ranking','sequence', 'labels','binary', 'kernel','variance', 'reference request','perceptron','math', 'cost function','tools','gaussian','career', 'management', 'learning', 'time', 'research',\n",
    "'education', 'implementation', 'processing', 'methods', 'code','community','finance','automation','marketing','genetic','efficiency','word','features', 'pipelines','methodology','history', 'search','google',\n",
    "'difference','energy','privacy', 'confidence', 'experiments', 'image','recommendation', 'categories', 'definitions','metadata','theory', 'predict','state of the art', 'matrix', 'noise','twitter','sensors','game',\n",
    "'parallel', 'variance', 'json', 'library','books', 'anomaly','distance','numerical','gpu','aggregation','representation','sports','scoring', 'structured data', 'normalization', 'cuda', 'data formats', 'search engine',\n",
    "'momentum' , 'parsing', 'indexing', 'counts' , 'parametric','data product', 'reshape', 'gradient', 'manhattan', 'convergence', 'parameter', 'competitions', 'reductions', 'markov','notation','labelling','sparse', 'tokenization',\n",
    "'corpus','coursera','anonymization','generalization','pooling','parallelism','metaheuristics','overfitting','duplicate records','homework','tpu','encoder','self driving','convolution','beginner','csv',\n",
    "'terminology', 'geospatial','bias','distributed','score','hardware','neural','estimators','nn','ml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_list = tail+red_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_and_skills_reduced = jobs_skills.drop(columns={*reduced_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244681, 238)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_and_skills_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## send to database on aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "                       .format(user=user, host = host,\n",
    "                               pw=password,\n",
    "                               db=dbname))\n",
    "jobs_and_skills_reduced.to_sql(con=engine, name='dash_table_V3', if_exists='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244681, 252)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 =pd.read_sql('SELECT * from dash_table_V3', con=conn)\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = jobs_and_skills_reduced.columns.to_list()\n",
    "skills = cols[8:]\n",
    "skills.insert(0,'job_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job_title', 'machine learning', 'python', 'neural network', 'deep learning', 'classification', 'keras', 'scikit learn', 'tensorflow', 'nlp', 'r', 'time series', 'data mining', 'regression', 'cnn', 'clustering', 'predictive modeling', 'pandas', 'lstm', 'statistics', 'feature selection', 'random forest', 'image classification', 'decision trees', 'text mining', 'linear regression', 'data cleaning', 'visualization', 'reinforcement learning', 'logistic regression', 'rnn', 'bigdata', 'xgboost', 'svm', 'cross validation', 'feature engineering', 'computer vision', 'recommender system', 'algorithms', 'optimization', 'unsupervised learning', 'prediction', 'preprocessing', 'word embeddings', 'pytorch', 'feature extraction', 'supervised learning', 'word2vec', 'anomaly detection', 'numpy', 'pca', 'apache spark', 'image recognition', 'probability', 'orange', 'dimensionality reduction', 'object detection', 'gan', 'graphs', 'model selection', 'forecasting', 'matlab', 'matplotlib', 'sentiment analysis', 'data analysis', 'hyperparameter tuning', 'transfer learning', 'ensemble modeling', 'apache hadoop', 'information retrieval', 'nltk', 'pyspark', 'bert', 'generative models', 'jupyter', 'plotting', 'named entity recognition', 'lda', 'embeddings', 'forecast', 'databases', 'confusion matrix', 'social network analysis', 'bayesian', 'sql', 'gensim', 'boosting', 'transformer', 'seaborn', 'data imputation', 'opencv', 'machine translation', 'weka', 'scipy', 'association rules', 'java', 'descriptive statistics', 'excel', 'data augmentation', 'object recognition', 'yolo', 'ocr', 'linear algebra', 'gbm', 'online learning', 'aws', 'rstudio', 'theano', 'genetic algorithms', 'ai', 'classifier', 'bayesian networks', 'anaconda', 'text classification', 'azure ml', 'scala', 'clusters', 'inception', 'data wrangling', 'error handling', 'scraping', 'lightgbm', 'programming', 'mathematics', 'spacy', 'survival analysis', 'tableau', 'churn', 'image segmentation', 'information theory', 'scalability', 'map reduce', 'javascript', 'market basket analysis', 'ggplot2', 'regex', 'nosql', 'glm', 'caffe', 'ensemble', 'annotation', 'bioinformatics', 'sas', 'simulation', 'powerbi', 'cloud computing', 'monte carlo', 'knowledge base', 'arima', 'auc', 'open source', 'mongodb', 'probabilistic programming', 'nvidia', 'web scraping', 'octave', 'software development', 'hive', 'active learning', 'c', 'chatbot', 'ml', 'dplyr', 'lasso', 'linux', 'torch', 'neo4j', 'crawling', 'etl', 'statsmodels', 'project planning', '3d reconstruction', 'sagemaker', 'nlg', 'shap', 'interpretation', 'julia', 'pattern recognition', 'question answering', 'meta learning', 'cloud', 'h2o', 'deepmind', 'data engineering', '.net', 'version control', 'infographics', 'apache pig', 'google cloud', 'tesseract', 'ann', 'automl', 'pruning', 'lsi', 'stata', 'spss', 'redshift', 'anova', 'dynamic programming', 'ner', 'bagging', 'plotly', 'apache kafka', 'bokeh', 'information extraction', 'knime', 'stemming', 'aws lambda', 'parquet', 'frequentist', 'sap', 'mxnet', 'linear programming', 'cart', 'mlflow', 'hbase', 'arrow', 'dashboards', 'hana', 'chainer', 'c++', 'exploitation', 'ibm watson', 'estimation', 'imputation', 'knowledge graph', 'data visualization', 'hadoop', 'pig', 'scikit', 'sklearn', 'spark']\n"
     ]
    }
   ],
   "source": [
    "print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = jobs_and_skills_reduced.groupby(['posted_date','state','term'])[skills].sum().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>machine learning</th>\n",
       "      <th>python</th>\n",
       "      <th>neural network</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>classification</th>\n",
       "      <th>keras</th>\n",
       "      <th>scikit learn</th>\n",
       "      <th>tensorflow</th>\n",
       "      <th>nlp</th>\n",
       "      <th>r</th>\n",
       "      <th>...</th>\n",
       "      <th>ibm watson</th>\n",
       "      <th>estimation</th>\n",
       "      <th>imputation</th>\n",
       "      <th>knowledge graph</th>\n",
       "      <th>data visualization</th>\n",
       "      <th>hadoop</th>\n",
       "      <th>pig</th>\n",
       "      <th>scikit</th>\n",
       "      <th>sklearn</th>\n",
       "      <th>spark</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posted_date</th>\n",
       "      <th>state</th>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2020-04-22</th>\n",
       "      <th>AL</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                machine learning  python  neural network  \\\n",
       "posted_date state term                                                     \n",
       "2020-04-22  AL    data analyst                 0       0               0   \n",
       "            AZ    data analyst                 0       0               0   \n",
       "            CA    data analyst                 0       2               0   \n",
       "            CO    data analyst                 0       0               0   \n",
       "            CT    data analyst                 0       0               0   \n",
       "\n",
       "                                deep learning  classification  keras  \\\n",
       "posted_date state term                                                 \n",
       "2020-04-22  AL    data analyst              0               0      0   \n",
       "            AZ    data analyst              0               0      0   \n",
       "            CA    data analyst              0               1      0   \n",
       "            CO    data analyst              0               0      0   \n",
       "            CT    data analyst              0               0      0   \n",
       "\n",
       "                                scikit learn  tensorflow  nlp  r  ...  \\\n",
       "posted_date state term                                            ...   \n",
       "2020-04-22  AL    data analyst             0           0    0  0  ...   \n",
       "            AZ    data analyst             0           0    0  0  ...   \n",
       "            CA    data analyst             0           0    0  2  ...   \n",
       "            CO    data analyst             0           0    0  0  ...   \n",
       "            CT    data analyst             0           0    0  0  ...   \n",
       "\n",
       "                                ibm watson  estimation  imputation  \\\n",
       "posted_date state term                                               \n",
       "2020-04-22  AL    data analyst           0           0           0   \n",
       "            AZ    data analyst           0           0           0   \n",
       "            CA    data analyst           0           0           0   \n",
       "            CO    data analyst           0           0           0   \n",
       "            CT    data analyst           0           0           0   \n",
       "\n",
       "                                knowledge graph  data visualization  hadoop  \\\n",
       "posted_date state term                                                        \n",
       "2020-04-22  AL    data analyst                0                   0       0   \n",
       "            AZ    data analyst                0                   0       0   \n",
       "            CA    data analyst                0                   2       0   \n",
       "            CO    data analyst                0                   0       0   \n",
       "            CT    data analyst                0                   0       0   \n",
       "\n",
       "                                pig  scikit  sklearn  spark  \n",
       "posted_date state term                                       \n",
       "2020-04-22  AL    data analyst    0       0        0      0  \n",
       "            AZ    data analyst    0       0        0      0  \n",
       "            CA    data analyst    0       0        0      0  \n",
       "            CO    data analyst    0       0        0      0  \n",
       "            CT    data analyst    0       0        0      0  \n",
       "\n",
       "[5 rows x 231 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped2 = jobs_and_skills_reduced.groupby(['posted_date','state','term'])['job_title'].count().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>python</th>\n",
       "      <th>neural network</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>classification</th>\n",
       "      <th>keras</th>\n",
       "      <th>scikit learn</th>\n",
       "      <th>tensorflow</th>\n",
       "      <th>nlp</th>\n",
       "      <th>...</th>\n",
       "      <th>ibm watson</th>\n",
       "      <th>estimation</th>\n",
       "      <th>imputation</th>\n",
       "      <th>knowledge graph</th>\n",
       "      <th>data visualization</th>\n",
       "      <th>hadoop</th>\n",
       "      <th>pig</th>\n",
       "      <th>scikit</th>\n",
       "      <th>sklearn</th>\n",
       "      <th>spark</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posted_date</th>\n",
       "      <th>state</th>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2020-04-22</th>\n",
       "      <th>AL</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                job_title  machine learning  python  \\\n",
       "posted_date state term                                                \n",
       "2020-04-22  AL    data analyst          1                 0       0   \n",
       "            AZ    data analyst          3                 0       0   \n",
       "            CA    data analyst          5                 0       2   \n",
       "            CO    data analyst          1                 0       0   \n",
       "            CT    data analyst          1                 0       0   \n",
       "\n",
       "                                neural network  deep learning  classification  \\\n",
       "posted_date state term                                                          \n",
       "2020-04-22  AL    data analyst               0              0               0   \n",
       "            AZ    data analyst               0              0               0   \n",
       "            CA    data analyst               0              0               1   \n",
       "            CO    data analyst               0              0               0   \n",
       "            CT    data analyst               0              0               0   \n",
       "\n",
       "                                keras  scikit learn  tensorflow  nlp  ...  \\\n",
       "posted_date state term                                                ...   \n",
       "2020-04-22  AL    data analyst      0             0           0    0  ...   \n",
       "            AZ    data analyst      0             0           0    0  ...   \n",
       "            CA    data analyst      0             0           0    0  ...   \n",
       "            CO    data analyst      0             0           0    0  ...   \n",
       "            CT    data analyst      0             0           0    0  ...   \n",
       "\n",
       "                                ibm watson  estimation  imputation  \\\n",
       "posted_date state term                                               \n",
       "2020-04-22  AL    data analyst           0           0           0   \n",
       "            AZ    data analyst           0           0           0   \n",
       "            CA    data analyst           0           0           0   \n",
       "            CO    data analyst           0           0           0   \n",
       "            CT    data analyst           0           0           0   \n",
       "\n",
       "                                knowledge graph  data visualization  hadoop  \\\n",
       "posted_date state term                                                        \n",
       "2020-04-22  AL    data analyst                0                   0       0   \n",
       "            AZ    data analyst                0                   0       0   \n",
       "            CA    data analyst                0                   2       0   \n",
       "            CO    data analyst                0                   0       0   \n",
       "            CT    data analyst                0                   0       0   \n",
       "\n",
       "                                pig  scikit  sklearn  spark  \n",
       "posted_date state term                                       \n",
       "2020-04-22  AL    data analyst    0       0        0      0  \n",
       "            AZ    data analyst    0       0        0      0  \n",
       "            CA    data analyst    0       0        0      0  \n",
       "            CO    data analyst    0       0        0      0  \n",
       "            CT    data analyst    0       0        0      0  \n",
       "\n",
       "[5 rows x 231 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr = pd.concat([grouped2, grouped],axis =1)\n",
    "gr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.to_csv('C:\\\\Users\\\\mh4pk\\\\Downloads\\\\grouped_april_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>python</th>\n",
       "      <th>neural network</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>classification</th>\n",
       "      <th>keras</th>\n",
       "      <th>scikit learn</th>\n",
       "      <th>tensorflow</th>\n",
       "      <th>nlp</th>\n",
       "      <th>...</th>\n",
       "      <th>ibm watson</th>\n",
       "      <th>estimation</th>\n",
       "      <th>imputation</th>\n",
       "      <th>knowledge graph</th>\n",
       "      <th>data visualization</th>\n",
       "      <th>hadoop</th>\n",
       "      <th>pig</th>\n",
       "      <th>scikit</th>\n",
       "      <th>sklearn</th>\n",
       "      <th>spark</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posted_date</th>\n",
       "      <th>state</th>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2020-04-22</th>\n",
       "      <th>AL</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT</th>\n",
       "      <th>data analyst</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                count  machine learning  python  \\\n",
       "posted_date state term                                            \n",
       "2020-04-22  AL    data analyst      1                 0       0   \n",
       "            AZ    data analyst      3                 0       0   \n",
       "            CA    data analyst      5                 0       2   \n",
       "            CO    data analyst      1                 0       0   \n",
       "            CT    data analyst      1                 0       0   \n",
       "\n",
       "                                neural network  deep learning  classification  \\\n",
       "posted_date state term                                                          \n",
       "2020-04-22  AL    data analyst               0              0               0   \n",
       "            AZ    data analyst               0              0               0   \n",
       "            CA    data analyst               0              0               1   \n",
       "            CO    data analyst               0              0               0   \n",
       "            CT    data analyst               0              0               0   \n",
       "\n",
       "                                keras  scikit learn  tensorflow  nlp  ...  \\\n",
       "posted_date state term                                                ...   \n",
       "2020-04-22  AL    data analyst      0             0           0    0  ...   \n",
       "            AZ    data analyst      0             0           0    0  ...   \n",
       "            CA    data analyst      0             0           0    0  ...   \n",
       "            CO    data analyst      0             0           0    0  ...   \n",
       "            CT    data analyst      0             0           0    0  ...   \n",
       "\n",
       "                                ibm watson  estimation  imputation  \\\n",
       "posted_date state term                                               \n",
       "2020-04-22  AL    data analyst           0           0           0   \n",
       "            AZ    data analyst           0           0           0   \n",
       "            CA    data analyst           0           0           0   \n",
       "            CO    data analyst           0           0           0   \n",
       "            CT    data analyst           0           0           0   \n",
       "\n",
       "                                knowledge graph  data visualization  hadoop  \\\n",
       "posted_date state term                                                        \n",
       "2020-04-22  AL    data analyst                0                   0       0   \n",
       "            AZ    data analyst                0                   0       0   \n",
       "            CA    data analyst                0                   2       0   \n",
       "            CO    data analyst                0                   0       0   \n",
       "            CT    data analyst                0                   0       0   \n",
       "\n",
       "                                pig  scikit  sklearn  spark  \n",
       "posted_date state term                                       \n",
       "2020-04-22  AL    data analyst    0       0        0      0  \n",
       "            AZ    data analyst    0       0        0      0  \n",
       "            CA    data analyst    0       0        0      0  \n",
       "            CO    data analyst    0       0        0      0  \n",
       "            CT    data analyst    0       0        0      0  \n",
       "\n",
       "[5 rows x 231 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.rename(columns={'job_title':'count'}, inplace = True)\n",
    "gr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.to_csv('C:\\\\Users\\\\mh4pk\\\\Downloads\\\\grouped_april_final_for_dash.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posted_date</th>\n",
       "      <th>state</th>\n",
       "      <th>term</th>\n",
       "      <th>count</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>python</th>\n",
       "      <th>neural network</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>classification</th>\n",
       "      <th>keras</th>\n",
       "      <th>...</th>\n",
       "      <th>ibm watson</th>\n",
       "      <th>estimation</th>\n",
       "      <th>imputation</th>\n",
       "      <th>knowledge graph</th>\n",
       "      <th>data visualization</th>\n",
       "      <th>hadoop</th>\n",
       "      <th>pig</th>\n",
       "      <th>scikit</th>\n",
       "      <th>sklearn</th>\n",
       "      <th>spark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>AL</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>AZ</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>CA</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>CO</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>CT</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  posted_date state          term  count  machine learning  python  \\\n",
       "0  2020-04-22    AL  data analyst      1                 0       0   \n",
       "1  2020-04-22    AZ  data analyst      3                 0       0   \n",
       "2  2020-04-22    CA  data analyst      5                 0       2   \n",
       "3  2020-04-22    CO  data analyst      1                 0       0   \n",
       "4  2020-04-22    CT  data analyst      1                 0       0   \n",
       "\n",
       "   neural network  deep learning  classification  keras  ...  ibm watson  \\\n",
       "0               0              0               0      0  ...           0   \n",
       "1               0              0               0      0  ...           0   \n",
       "2               0              0               1      0  ...           0   \n",
       "3               0              0               0      0  ...           0   \n",
       "4               0              0               0      0  ...           0   \n",
       "\n",
       "   estimation  imputation  knowledge graph  data visualization  hadoop  pig  \\\n",
       "0           0           0                0                   0       0    0   \n",
       "1           0           0                0                   0       0    0   \n",
       "2           0           0                0                   2       0    0   \n",
       "3           0           0                0                   0       0    0   \n",
       "4           0           0                0                   0       0    0   \n",
       "\n",
       "   scikit  sklearn  spark  \n",
       "0       0        0      0  \n",
       "1       0        0      0  \n",
       "2       0        0      0  \n",
       "3       0        0      0  \n",
       "4       0        0      0  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr2 = gr.reset_index()\n",
    "gr2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "                       .format(user=user, host = host,\n",
    "                               pw=password,\n",
    "                               db=dbname))\n",
    "gr2.to_sql(con=engine, name='dash_grouped_2_try', if_exists='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32097, 234)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32097, 235)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 =pd.read_sql('SELECT * from dash_grouped_2_try', con=conn)\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>state</th>\n",
       "      <th>term</th>\n",
       "      <th>count</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>python</th>\n",
       "      <th>neural network</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>classification</th>\n",
       "      <th>...</th>\n",
       "      <th>ibm watson</th>\n",
       "      <th>estimation</th>\n",
       "      <th>imputation</th>\n",
       "      <th>knowledge graph</th>\n",
       "      <th>data visualization</th>\n",
       "      <th>hadoop</th>\n",
       "      <th>pig</th>\n",
       "      <th>scikit</th>\n",
       "      <th>sklearn</th>\n",
       "      <th>spark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>AL</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>AZ</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>CA</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>CO</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>CT</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index posted_date state          term  count  machine learning  python  \\\n",
       "0      0  2020-04-22    AL  data analyst      1                 0       0   \n",
       "1      1  2020-04-22    AZ  data analyst      3                 0       0   \n",
       "2      2  2020-04-22    CA  data analyst      5                 0       2   \n",
       "3      3  2020-04-22    CO  data analyst      1                 0       0   \n",
       "4      4  2020-04-22    CT  data analyst      1                 0       0   \n",
       "\n",
       "   neural network  deep learning  classification  ...  ibm watson  estimation  \\\n",
       "0               0              0               0  ...           0           0   \n",
       "1               0              0               0  ...           0           0   \n",
       "2               0              0               1  ...           0           0   \n",
       "3               0              0               0  ...           0           0   \n",
       "4               0              0               0  ...           0           0   \n",
       "\n",
       "   imputation  knowledge graph  data visualization  hadoop  pig  scikit  \\\n",
       "0           0                0                   0       0    0       0   \n",
       "1           0                0                   0       0    0       0   \n",
       "2           0                0                   2       0    0       0   \n",
       "3           0                0                   0       0    0       0   \n",
       "4           0                0                   0       0    0       0   \n",
       "\n",
       "   sklearn  spark  \n",
       "0        0      0  \n",
       "1        0      0  \n",
       "2        0      0  \n",
       "3        0      0  \n",
       "4        0      0  \n",
       "\n",
       "[5 rows x 235 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "grouped = pd.read_csv('C:\\\\Users\\\\mh4pk\\\\Downloads\\\\grouped_april_final_for_dash.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_da = grouped[grouped['term']=='data analyst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posted_date</th>\n",
       "      <th>state</th>\n",
       "      <th>term</th>\n",
       "      <th>count</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>python</th>\n",
       "      <th>neural network</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>classification</th>\n",
       "      <th>keras</th>\n",
       "      <th>...</th>\n",
       "      <th>ibm watson</th>\n",
       "      <th>estimation</th>\n",
       "      <th>imputation</th>\n",
       "      <th>knowledge graph</th>\n",
       "      <th>data visualization</th>\n",
       "      <th>hadoop</th>\n",
       "      <th>pig</th>\n",
       "      <th>scikit</th>\n",
       "      <th>sklearn</th>\n",
       "      <th>spark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>AL</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>AZ</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>CA</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>CO</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>CT</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  posted_date state          term  count  machine learning  python  \\\n",
       "0  2020-04-22    AL  data analyst      1                 0       0   \n",
       "1  2020-04-22    AZ  data analyst      3                 0       0   \n",
       "2  2020-04-22    CA  data analyst      5                 0       2   \n",
       "3  2020-04-22    CO  data analyst      1                 0       0   \n",
       "4  2020-04-22    CT  data analyst      1                 0       0   \n",
       "\n",
       "   neural network  deep learning  classification  keras  ...  ibm watson  \\\n",
       "0               0              0               0      0  ...           0   \n",
       "1               0              0               0      0  ...           0   \n",
       "2               0              0               1      0  ...           0   \n",
       "3               0              0               0      0  ...           0   \n",
       "4               0              0               0      0  ...           0   \n",
       "\n",
       "   estimation  imputation  knowledge graph  data visualization  hadoop  pig  \\\n",
       "0           0           0                0                   0       0    0   \n",
       "1           0           0                0                   0       0    0   \n",
       "2           0           0                0                   2       0    0   \n",
       "3           0           0                0                   0       0    0   \n",
       "4           0           0                0                   0       0    0   \n",
       "\n",
       "   scikit  sklearn  spark  \n",
       "0       0        0      0  \n",
       "1       0        0      0  \n",
       "2       0        0      0  \n",
       "3       0        0      0  \n",
       "4       0        0      0  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_da.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excel                        49987\n",
      "sql                          43565\n",
      "data analysis                28306\n",
      "tableau                      22116\n",
      "databases                    21126\n",
      "statistics                   20109\n",
      "dashboards                   19181\n",
      "visualization                17392\n",
      "programming                  16948\n",
      "python                       16298\n",
      "r                            12394\n",
      "data visualization           12009\n",
      "mathematics                  11636\n",
      "software development          9973\n",
      "cloud                         9839\n",
      "sas                           9567\n",
      "forecasting                   8481\n",
      "optimization                  8303\n",
      "etl                           7764\n",
      "data mining                   7218\n",
      "interpretation                6267\n",
      "sap                           6083\n",
      "machine learning              5401\n",
      "classification                5148\n",
      "c                             4691\n",
      "aws                           4359\n",
      "powerbi                       4215\n",
      "forecast                      3999\n",
      "regression                    3895\n",
      "graphs                        3657\n",
      "java                          3349\n",
      "algorithms                    3017\n",
      "spss                          2928\n",
      "javascript                    2628\n",
      "hadoop                        2282\n",
      "data engineering              2177\n",
      "ai                            1841\n",
      "predictive modeling           1710\n",
      "project planning              1693\n",
      "spark                         1650\n",
      "redshift                      1514\n",
      "simulation                    1350\n",
      ".net                          1323\n",
      "linux                         1265\n",
      "stata                         1195\n",
      "hive                          1092\n",
      "scalability                   1073\n",
      "knowledge base                1054\n",
      "inception                     1049\n",
      "nosql                         1048\n",
      "matlab                        1007\n",
      "estimation                     943\n",
      "c++                            882\n",
      "open source                    864\n",
      "clustering                     796\n",
      "cloud computing                789\n",
      "probability                    709\n",
      "data cleaning                  706\n",
      "version control                671\n",
      "google cloud                   651\n",
      "pandas                         565\n",
      "time series                    558\n",
      "scala                          546\n",
      "hana                           533\n",
      "infographics                   487\n",
      "data wrangling                 482\n",
      "exploitation                   467\n",
      "linear regression              433\n",
      "descriptive statistics         411\n",
      "orange                         405\n",
      "deep learning                  380\n",
      "bioinformatics                 375\n",
      "logistic regression            365\n",
      "mongodb                        361\n",
      "numpy                          358\n",
      "prediction                     339\n",
      "jupyter                        336\n",
      "decision trees                 325\n",
      "online learning                322\n",
      "nlp                            285\n",
      "pyspark                        269\n",
      "churn                          254\n",
      "text mining                    235\n",
      "pig                            217\n",
      "tensorflow                     203\n",
      "matplotlib                     203\n",
      "hbase                          189\n",
      "anomaly detection              188\n",
      "information retrieval          165\n",
      "anova                          164\n",
      "random forest                  155\n",
      "bayesian                       151\n",
      "crawling                       148\n",
      "pattern recognition            145\n",
      "scraping                       144\n",
      "ann                            140\n",
      "clusters                       139\n",
      "apache spark                   138\n",
      "plotly                         133\n",
      "computer vision                125\n",
      "error handling                 121\n",
      "knime                          118\n",
      "web scraping                   115\n",
      "scipy                          113\n",
      "stemming                       106\n",
      "survival analysis               97\n",
      "ocr                             97\n",
      "ensemble                        95\n",
      "feature engineering             92\n",
      "neo4j                           92\n",
      "cnn                             91\n",
      "cart                            90\n",
      "monte carlo                     90\n",
      "julia                           88\n",
      "rstudio                         88\n",
      "boosting                        87\n",
      "map reduce                      87\n",
      "arrow                           85\n",
      "social network analysis         84\n",
      "annotation                      84\n",
      "nvidia                          80\n",
      "keras                           79\n",
      "pytorch                         78\n",
      "pca                             74\n",
      "sentiment analysis              73\n",
      "unsupervised learning           70\n",
      "seaborn                         65\n",
      "active learning                 64\n",
      "preprocessing                   64\n",
      "parquet                         63\n",
      "sagemaker                       61\n",
      "ibm watson                      60\n",
      "imputation                      54\n",
      "chatbot                         51\n",
      "ggplot2                         51\n",
      "torch                           47\n",
      "arima                           46\n",
      "linear algebra                  44\n",
      "regex                           44\n",
      "svm                             42\n",
      "nltk                            42\n",
      "bigdata                         41\n",
      "bokeh                           41\n",
      "aws lambda                      39\n",
      "neural network                  38\n",
      "glm                             37\n",
      "linear programming              37\n",
      "model selection                 36\n",
      "dynamic programming             35\n",
      "scikit                          35\n",
      "anaconda                        34\n",
      "feature selection               34\n",
      "dimensionality reduction        33\n",
      "h2o                             33\n",
      "weka                            32\n",
      "sklearn                         31\n",
      "dplyr                           31\n",
      "plotting                        30\n",
      "apache hadoop                   30\n",
      "genetic algorithms              30\n",
      "cross validation                29\n",
      "association rules               25\n",
      "xgboost                         25\n",
      "market basket analysis          25\n",
      "octave                          24\n",
      "reinforcement learning          23\n",
      "apache kafka                    21\n",
      "scikit learn                    20\n",
      "azure ml                        20\n",
      "image recognition               19\n",
      "lda                             16\n",
      "theano                          16\n",
      "supervised learning             16\n",
      "rnn                             15\n",
      "named entity recognition        14\n",
      "lsi                             14\n",
      "caffe                           13\n",
      "machine translation             13\n",
      "transformer                     13\n",
      "ensemble modeling               12\n",
      "statsmodels                     12\n",
      "nlg                             12\n",
      "spacy                           11\n",
      "gbm                             11\n",
      "word2vec                        11\n",
      "apache pig                       9\n",
      "transfer learning                9\n",
      "gensim                           9\n",
      "feature extraction               8\n",
      "knowledge graph                  8\n",
      "bayesian networks                8\n",
      "classifier                       8\n",
      "automl                           6\n",
      "text classification              6\n",
      "data imputation                  6\n",
      "data augmentation                6\n",
      "auc                              5\n",
      "mlflow                           5\n",
      "lstm                             5\n",
      "mxnet                            5\n",
      "bagging                          4\n",
      "image segmentation               4\n",
      "information extraction           4\n",
      "yolo                             4\n",
      "opencv                           4\n",
      "frequentist                      4\n",
      "confusion matrix                 4\n",
      "bert                             4\n",
      "gan                              4\n",
      "image classification             3\n",
      "shap                             3\n",
      "lasso                            3\n",
      "ner                              3\n",
      "information theory               3\n",
      "embeddings                       2\n",
      "tesseract                        2\n",
      "probabilistic programming        2\n",
      "recommender system               2\n",
      "lightgbm                         2\n",
      "generative models                2\n",
      "object detection                 1\n",
      "hyperparameter tuning            1\n",
      "chainer                          1\n",
      "3d reconstruction                1\n",
      "meta learning                    1\n",
      "pruning                          1\n",
      "word embeddings                  1\n",
      "question answering               0\n",
      "deepmind                         0\n",
      "object recognition               0\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(grouped_da.iloc[:,4:].sum().astype(int).sort_values(ascending= False).head(240).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ds = grouped[grouped['term']=='data scientist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python                       25154\n",
      "machine learning             22851\n",
      "statistics                   21124\n",
      "sql                          18172\n",
      "programming                  16957\n",
      "r                            16632\n",
      "mathematics                  14930\n",
      "algorithms                   13140\n",
      "data analysis                10863\n",
      "visualization                 9874\n",
      "cloud                         9748\n",
      "ai                            8175\n",
      "sas                           8143\n",
      "databases                     7945\n",
      "tableau                       7715\n",
      "spark                         7336\n",
      "aws                           7319\n",
      "deep learning                 7295\n",
      "java                          7085\n",
      "optimization                  6858\n",
      "excel                         6851\n",
      "data mining                   6310\n",
      "data visualization            5969\n",
      "hadoop                        5824\n",
      "tensorflow                    5218\n",
      "regression                    5116\n",
      "software development          4712\n",
      "predictive modeling           4042\n",
      "c++                           3937\n",
      "classification                3918\n",
      "dashboards                    3748\n",
      "pytorch                       3591\n",
      "forecasting                   3555\n",
      "nlp                           3503\n",
      "scala                         3268\n",
      "data engineering              3066\n",
      "clustering                    3051\n",
      "etl                           2865\n",
      "hive                          2847\n",
      "computer vision               2654\n",
      "matlab                        2590\n",
      "c                             2531\n",
      "simulation                    2428\n",
      "keras                         2272\n",
      "open source                   2244\n",
      "interpretation                2177\n",
      "time series                   2108\n",
      "nosql                         2104\n",
      "pandas                        2017\n",
      "cloud computing               1804\n",
      "linux                         1779\n",
      "javascript                    1697\n",
      "numpy                         1668\n",
      "google cloud                  1556\n",
      "prediction                    1529\n",
      "spss                          1469\n",
      "decision trees                1385\n",
      "version control               1373\n",
      "probability                   1368\n",
      "bayesian                      1352\n",
      "reinforcement learning        1266\n",
      "powerbi                       1220\n",
      "anomaly detection             1155\n",
      "sagemaker                     1126\n",
      "redshift                      1112\n",
      "scalability                   1106\n",
      "pyspark                       1098\n",
      "bioinformatics                1059\n",
      "graphs                        1021\n",
      "logistic regression           1004\n",
      "sap                            999\n",
      "feature engineering            990\n",
      "text mining                    958\n",
      "mongodb                        939\n",
      "forecast                       882\n",
      "mxnet                          869\n",
      "jupyter                        824\n",
      "data wrangling                 814\n",
      "apache spark                   811\n",
      "scipy                          776\n",
      "nvidia                         770\n",
      "stata                          769\n",
      "pig                            761\n",
      "estimation                     738\n",
      "ensemble                       734\n",
      "random forest                  718\n",
      "information retrieval          682\n",
      "matplotlib                     665\n",
      "unsupervised learning          632\n",
      "linear algebra                 627\n",
      "pattern recognition            572\n",
      "ibm watson                     549\n",
      "cnn                            538\n",
      "data cleaning                  535\n",
      "caffe                          530\n",
      "boosting                       524\n",
      "linear regression              515\n",
      "online learning                508\n",
      "julia                          506\n",
      "hbase                          500\n",
      "svm                            495\n",
      "neural network                 467\n",
      "churn                          445\n",
      "h2o                            443\n",
      "survival analysis              433\n",
      "theano                         418\n",
      "neo4j                          414\n",
      "sentiment analysis             407\n",
      "inception                      407\n",
      "nltk                           403\n",
      ".net                           379\n",
      "spacy                          374\n",
      "scikit                         363\n",
      "xgboost                        361\n",
      "opencv                         349\n",
      "plotly                         345\n",
      "bert                           338\n",
      "annotation                     332\n",
      "active learning                324\n",
      "sklearn                        315\n",
      "clusters                       309\n",
      "feature selection              308\n",
      "preprocessing                  308\n",
      "object detection               303\n",
      "rnn                            290\n",
      "supervised learning            283\n",
      "torch                          279\n",
      "exploitation                   275\n",
      "model selection                273\n",
      "knowledge base                 263\n",
      "information extraction         259\n",
      "deepmind                       257\n",
      "project planning               256\n",
      "social network analysis        252\n",
      "descriptive statistics         244\n",
      "hana                           239\n",
      "lstm                           234\n",
      "azure ml                       231\n",
      "dimensionality reduction       230\n",
      "transfer learning              227\n",
      "apache kafka                   227\n",
      "seaborn                        215\n",
      "imputation                     214\n",
      "weka                           205\n",
      "image recognition              204\n",
      "feature extraction             189\n",
      "ggplot2                        186\n",
      "map reduce                     180\n",
      "scikit learn                   177\n",
      "scraping                       171\n",
      "glm                            170\n",
      "monte carlo                    163\n",
      "bokeh                          158\n",
      "pca                            157\n",
      "ensemble modeling              153\n",
      "gensim                         151\n",
      "ocr                            148\n",
      "mlflow                         144\n",
      "knowledge graph                144\n",
      "anova                          143\n",
      "chatbot                        139\n",
      "statsmodels                    138\n",
      "linear programming             136\n",
      "web scraping                   134\n",
      "apache hadoop                  132\n",
      "gbm                            132\n",
      "parquet                        129\n",
      "gan                            121\n",
      "machine translation            117\n",
      "rstudio                        116\n",
      "aws lambda                     115\n",
      "dynamic programming            114\n",
      "genetic algorithms             114\n",
      "embeddings                     112\n",
      "confusion matrix               106\n",
      "dplyr                          105\n",
      "word2vec                       103\n",
      "image segmentation             101\n",
      "arima                          101\n",
      "ann                            100\n",
      "automl                          99\n",
      "text classification             99\n",
      "lda                             97\n",
      "ner                             93\n",
      "image classification            91\n",
      "knime                           91\n",
      "named entity recognition        84\n",
      "bayesian networks               84\n",
      "association rules               82\n",
      "generative models               76\n",
      "cart                            76\n",
      "anaconda                        75\n",
      "meta learning                   75\n",
      "transformer                     75\n",
      "question answering              73\n",
      "data imputation                 69\n",
      "data augmentation               69\n",
      "lightgbm                        66\n",
      "orange                          64\n",
      "frequentist                     64\n",
      "infographics                    62\n",
      "nlg                             58\n",
      "lasso                           55\n",
      "stemming                        52\n",
      "information theory              51\n",
      "bigdata                         47\n",
      "crawling                        47\n",
      "probabilistic programming       47\n",
      "classifier                      44\n",
      "cross validation                44\n",
      "3d reconstruction               42\n",
      "hyperparameter tuning           41\n",
      "pruning                         39\n",
      "bagging                         39\n",
      "market basket analysis          38\n",
      "recommender system              35\n",
      "shap                            33\n",
      "word embeddings                 33\n",
      "octave                          32\n",
      "lsi                             29\n",
      "chainer                         29\n",
      "tesseract                       26\n",
      "auc                             26\n",
      "arrow                           24\n",
      "regex                           23\n",
      "yolo                            22\n",
      "plotting                        22\n",
      "object recognition              21\n",
      "apache pig                      20\n",
      "error handling                  13\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(grouped_ds.iloc[:,4:].sum().astype(int).sort_values(ascending= False).head(240).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd3 =pd.read_csv('C:/Users/mh4pk/Downloads/april-10-fixed.csv', index_col = 'Unnamed: 0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss= dd3.groupby('company')['description'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = ss.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = comps.sort_values(by='description',ascending=False)[:20].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_companies = companies.drop(['index'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_companies.to_csv('C:/Users/mh4pk/Downloads/top_companies.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
